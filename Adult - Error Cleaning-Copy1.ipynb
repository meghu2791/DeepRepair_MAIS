{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import calendar\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "import pickle\n",
    "import gensim\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import metrics\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import FastText\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from keras.models import load_model\n",
    "from enum import Enum\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 7\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AdultErrors.csv', encoding='utf8', dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educationnum</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>private</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>prof-specialty</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;50k:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>private</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>craft-repair</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>mxle</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>&lt;=50k:0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age workclass  education educationnum       maritalstatus      occupation  \\\n",
       "0  47   private  doctorate           16  married-civ-spouse  prof-specialty   \n",
       "1  27   private    hs-grad            9  married-civ-spouse    craft-repair   \n",
       "\n",
       "  relationship   race   sex hoursperweek        country   income  \n",
       "0      husband  white  male           60            NaN   >50k:0  \n",
       "1      husband  white  mxle           40  united-states  <=50k:0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3766"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "sum(df.isnull().values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEmpty = df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEmpty = dfEmpty.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Nan = df\n",
    "df_Nan = df_Nan[~df_Nan.isin(dfEmpty)].dropna()\n",
    "df_Nan.to_csv(\"AdultErrorsWithoutNan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"AdultWord2Vec.w2v\"\n",
    "word2vecModel = KeyedVectors.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(enumerate(dfEmpty.columns.astype('category').categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeMapping = {}\n",
    "for i,idx in enumerate(dfEmpty.columns):\n",
    "    attributeMapping[idx] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverseMapping = {y:x for x,y in attributeMapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Attribute Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('AdultMultiAttributeClassifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AdultMultiAttributeClassifierTokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(word2vecModel, model, tokenizer, rowWithMissingValue, missingType, topN=10):\n",
    "    \"\"\"\n",
    "    Returns the closest match for the missing attribute value\n",
    "    \"\"\"\n",
    "    output = dict()\n",
    "    for value in rowWithMissingValue:\n",
    "        try:\n",
    "            results = word2vecModel.wv.most_similar(value, topn=topN)\n",
    "            for match, confidence in results:\n",
    "                # Predicted type to be equal to the missing value\n",
    "                if predictAttribute(model, tokenizer, match) == missingType:\n",
    "                    if match in output and confidence <= output[match]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        output[match] = confidence            \n",
    "        except KeyError:\n",
    "            continue\n",
    "    return output.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAttribute(model, tokenizer, value):\n",
    "    \"\"\"\n",
    "    Classifies value parameter as its corresponding attribute\n",
    "    \"\"\"\n",
    "    value = [value]\n",
    "    sequences = tokenizer.texts_to_sequences(value)\n",
    "    testData = pad_sequences(sequences, maxlen=26)\n",
    "    predictions = model.predict(testData)\n",
    "    return attributeMapping[mapping[np.argmax(predictions[0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullRows = dfEmpty.values.tolist()\n",
    "rows = []\n",
    "#columnNames = ['ProviderNumber', 'HospitalName', 'Address1', 'City', 'ZipCode', 'CountyName', 'PhoneNumber','HospitalOwner','Condition','Sample']\n",
    "columnNames = dfEmpty.columns.tolist()\n",
    "for row in nullRows:\n",
    "    missingAttribute = None\n",
    "    removedNan = []\n",
    "    for i in range(len(row)):\n",
    "        if str(row[i]) != 'nan':\n",
    "            removedNan.append(row[i])\n",
    "        else:\n",
    "            missingAttribute = attributeMapping[columnNames[i]]\n",
    "    if missingAttribute is not None:\n",
    "        rows.append({tuple(removedNan):missingAttribute})\n",
    "    else:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImputedValue(missingRow, attributeType):\n",
    "    results = impute(word2vecModel, model, tokenizer, missingRow, attributeType, 100)\n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)[0] if results else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build verification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean = pd.read_csv('clean_adult_dataset_hc.csv', encoding='utf8', dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnique = dfClean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMapping = {}\n",
    "attributeNames = dfClean.columns.tolist()\n",
    "for i in attributeNames:\n",
    "    for j in attributeNames:\n",
    "        if i!=j:\n",
    "            if i in queryMapping:\n",
    "                queryMapping[i] = queryMapping.get(i) + ' and  ' + str(j + '==\"{}\"')\n",
    "            else:\n",
    "                queryMapping[i] = str(j + '==\"{}\"') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "inCorrect = 0\n",
    "incorrectPredictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in rows:\n",
    "    missingRow = list(row.keys())[0]\n",
    "    attribute = list(row.values())[0]\n",
    "    missingRow = [i.strip() for i in missingRow]\n",
    "    # Run the query\n",
    "    query = (queryMapping[inverseMapping[attribute]]).format(*missingRow)\n",
    "    outputDf = dfClean.query(query)\n",
    "    actual = outputDf.head(1)[inverseMapping[attribute]].to_string(index=False)\n",
    "    if actual == 'empty':\n",
    "        continue\n",
    "    predicted = getImputedValue(missingRow, attribute) \n",
    "    if predicted and actual == predicted[0]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        inCorrect += 1\n",
    "        incorrectPredictions.append((actual, predicted[0] if predicted else None)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "Details here: https://fasttext.cc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For truth validation read clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv('clean_adult_dataset_hc.csv',dtype=object, encoding='utf8', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dirty dataset from imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty = pd.read_csv('AdultErrorsWithoutNan.csv',dtype=object, encoding='utf8', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dirty.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_hosp = df_truth.values.tolist()\n",
    "combined_dirty = df_dirty.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_truth.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueValues = {}\n",
    "for i in df_truth.columns:\n",
    "    uniqueValues[i] = set(df_truth[i].tolist())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'AdultFastText.w2v'\n",
    "fastTextModel = KeyedVectors.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('AdultMultiAttributeClassifier.h5')\n",
    "with open('AdultMultiAttributeClassifierTokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(enumerate(sorted(df_truth.columns.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeMapping = {}\n",
    "for i,idx in enumerate(df_truth.columns):\n",
    "    attributeMapping[i] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAttribute(model, tokenizer, value):\n",
    "    \"\"\"\n",
    "    Classifies value parameter as its corresponding attribute\n",
    "    \"\"\"\n",
    "    value = [value]\n",
    "    sequences = tokenizer.texts_to_sequences(value)\n",
    "    testData = pad_sequences(sequences, maxlen=26)\n",
    "    predictions = model.predict(testData)\n",
    "    return mapping[np.argmax(predictions[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctCell(fastTextModel, model, tokenizer, row, topN=10):\n",
    "    cellValues = {}\n",
    "    output = dict()\n",
    "    isMistake = False\n",
    "    for cellIndex in range(len(row)):\n",
    "        currentCellValue = row[cellIndex]\n",
    "        if not currentCellValue in uniqueValues[attributeMapping[cellIndex]]:\n",
    "            isMistake = True\n",
    "            cellValues['mistakeDetected'] = currentCellValue\n",
    "            try:\n",
    "                predictions = fastTextModel.most_similar(currentCellValue, topn=topN)\n",
    "                for match, confidence in predictions:\n",
    "                # Predicted type to be equal to the missing value\n",
    "                    if predictAttribute(model, tokenizer, match) == columns[cellIndex]:\n",
    "                        if match in output and confidence <= output[match]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            output[match] = confidence\n",
    "            except:\n",
    "                possibleValues = uniqueValues[attributeMapping[cellIndex]]\n",
    "                maxScore = 0.0\n",
    "                for i in possibleValues:\n",
    "                    str1 = set(currentCellValue)\n",
    "                    str2 = set(i)\n",
    "                    score = float(len(str1 & str2)) / len(str1 | str2)\n",
    "                    if maxScore < score:\n",
    "                        maxScore = score\n",
    "                        output[i] = score\n",
    "    \n",
    "    if isMistake:\n",
    "        results = output.items()\n",
    "        predictedValue = sorted(results, key=lambda x: x[1], reverse=True)[0] if results else None\n",
    "        cellValues['predictedValue'] = predictedValue[0] if predictedValue else None\n",
    "        return cellValues\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnique = df_truth.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfUnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMapping = {}\n",
    "attributeNames = df_truth.columns.tolist()\n",
    "for i in attributeNames:\n",
    "    for j in attributeNames:\n",
    "        if i!=j:\n",
    "            if i in queryMapping:\n",
    "                queryMapping[i] = queryMapping.get(i) + ' and  ' + str(j + '==\"{}\"')\n",
    "            else:\n",
    "                queryMapping[i] = str(j + '==\"{}\"') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "inCorrect = 0\n",
    "incorrectPredictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in combined_dirty:\n",
    "    output = correctCell(fastTextModel, model, tokenizer, row, 15)\n",
    "    if output:\n",
    "        detectedError = output['mistakeDetected']\n",
    "        predictedValue = output['predictedValue']\n",
    "    \n",
    "        tempRow = row[:]\n",
    "        errorIndex = row.index(detectedError)\n",
    "        tempRow.remove(detectedError)\n",
    "\n",
    "        query = (queryMapping[columns[errorIndex]]).format(*tempRow)\n",
    "        outputDf = dfUnique.query(query)\n",
    "        actual = outputDf.head(1).values.tolist()[0][errorIndex]\n",
    "        \n",
    "        if actual == predictedValue:\n",
    "            correct += 1\n",
    "        else:\n",
    "            inCorrect += 1\n",
    "            incorrectPredictions.append((actual, detectedError, predictedValue, errorIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = correct / (correct + inCorrect) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorAnalysis = defaultdict(int)\n",
    "for actual, detectedError, predictedValue, errorIndex  in incorrectPredictions:\n",
    "    errorAnalysis[errorIndex] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(errorAnalysis)), list(errorAnalysis.values()), align='center')\n",
    "plt.xticks(range(len(errorAnalysis)), list(errorAnalysis.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverseMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
